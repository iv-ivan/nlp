{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Emails.csv\")\n",
    "texts = list(dataset[\"RawText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tools\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cleaning of texts\n",
    "_digits = re.compile('\\d')\n",
    "def contains_digits(d):\n",
    "    return bool(_digits.search(d))\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    words = text.split(\" \")\n",
    "    prepared_words = [word.lower() for word in words if len(word) > 1 and not contains_digits(word)]\n",
    "    texts[i] = prepared_words\n",
    "    \n",
    "connected_texts = [\" \".join(text) for text in texts]\n",
    "ps_texts = [\" \".join([ps.stem(word) for word in text]) for text in texts]\n",
    "lem_texts = [\" \".join([lemmatizer.lemmatize(word) for word in text]) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я очищаю от всех не буквенных символов (знаки препинания, цифры и тд), а также отбрасываю слова короче 2 букв. Также рядом создаю тексты с лемматизированным и стемизированным содержимым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department state 27076\n",
      "case doc 26520\n",
      "state case 26518\n",
      "unclassified department 26509\n",
      "doc date 26505\n",
      "state gov 11055\n",
      "date release 7479\n",
      "original message 7233\n",
      "gov sent 6501\n",
      "date unclassified 5421\n",
      "clintonemail com 4887\n",
      "mills cheryl 4415\n",
      "abedin huma 4083\n",
      "subject fw 3494\n",
      "sullivan jacob 3234\n",
      "abedinh state 2783\n",
      "com sent 2537\n",
      "millscd state 2375\n",
      "huma abedinh 2316\n",
      "pm subject 2291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#count most frequent bigrams\n",
    "counter = CountVectorizer(strip_accents='unicode', ngram_range=(2,2), stop_words='english')\n",
    "A = counter.fit_transform(connected_texts)\n",
    "\n",
    "A = np.sum(A, axis=0) #sum frequencies in all docs\n",
    "\n",
    "terms = {} #index to word\n",
    "for z in counter.vocabulary_:\n",
    "    terms[counter.vocabulary_[z]] = z\n",
    "    \n",
    "for k in xrange(20): #top-20 bigrams\n",
    "    j = np.unravel_index(A.argmax(), A.shape)[1]\n",
    "    print terms[j], A[0, j]\n",
    "    A[0, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ali taajw 21.3898943976\n",
      "_apecrets prg 21.3898943976\n",
      "_lewda lysched 21.3898943976\n",
      "_mrsiata nizenmenvarmars 21.3898943976\n",
      "_reunite arriericll 21.3898943976\n",
      "_rmuacartatmott rmaamaxatiamasm 21.3898943976\n",
      "_s_ peciaiassistants 21.3898943976\n",
      "_secreta ry_of_state_robs_sterling_ba 21.3898943976\n",
      "a_ maveff 21.3898943976\n",
      "a_pia ivene 21.3898943976\n",
      "aaad htmly 21.3898943976\n",
      "aat hacatiasierchassme 21.3898943976\n",
      "abba eban 21.3898943976\n",
      "abdelrahim oshi 21.3898943976\n",
      "abiola farida 21.3898943976\n",
      "abis syh 21.3898943976\n",
      "abot theiweb 21.3898943976\n",
      "aca demic 21.3898943976\n",
      "achtnn nepdc 21.3898943976\n",
      "aciout foreimi 21.3898943976\n"
     ]
    }
   ],
   "source": [
    "#max pmi collocations\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_documents(texts)\n",
    "res = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bigram in res[:20]:\n",
    "    print \" \".join(bigram[0]), bigram[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7945, 13416)\n"
     ]
    }
   ],
   "source": [
    "#extract features for clusterizzation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "counter = TfidfVectorizer(strip_accents='unicode', stop_words='english', max_df=0.9, min_df=0.005)\n",
    "A = counter.fit_transform(connected_texts).toarray()\n",
    "B = counter.fit_transform(ps_texts).toarray()\n",
    "C = counter.fit_transform(lem_texts).toarray()\n",
    "\n",
    "counter = TfidfVectorizer(strip_accents='unicode', ngram_range=(2,2), stop_words='english', max_df=0.9, min_df=0.005)\n",
    "D = counter.fit_transform(connected_texts).toarray()\n",
    "E = counter.fit_transform(ps_texts).toarray()\n",
    "F = counter.fit_transform(lem_texts).toarray()\n",
    "\n",
    "features = np.hstack((A, B, C, D, E, F))\n",
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7945, 13416) -> (7945, 100)\n"
     ]
    }
   ],
   "source": [
    "#reduce dimensions\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(100)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "A = lsa.fit_transform(features)\n",
    "print features.shape, \"->\", A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cluster, num of clusters is 30 (пока что)\n",
    "n = 30\n",
    "km = KMeans(n_clusters=n, init='k-means++', max_iter=500, n_init=100)\n",
    "result = km.fit_predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'sent sat', u'release mills', u'millscd state', u'department state', u'cc ses', u'abedin sent', u'june pm', u'abedin huma', u'tuesday september', u'release clintonemail', u'foia waiver', u'state department', u'subject agreement', u'ses o_shift', u'lona valmorou', u'mchale judith', u'state goy', u'state gov', u'jacob sullivanjj', u'huma abedin', u'sent tuesday', u'reines philippe', u'august pm', u'sent subject', u'pm abedinh', u'prime minister', u'jul subject', u'gov cc', u'unclassified department', u'pm subject', u'lauren jilotylc', u'pm secretary', u'message clintonemail', u'release sent', u'jacob sent', u'benghazi comm', u'state case', u'september pm', u'message mailto', u'sent thursday', u'aug subject', u'verma richard', u'agreement sensitive', u'cheryl sent', u'information redactions', u'select benghazi', u'huma sent', u'sent fri', u'subject speech', u'subject holbrooke', u'gov subject', u'gov huma', u'muscatine lissa', u'pm depart', u'northern ireland', u'valmoro lona', u'doc date', u'sullivanjj state', u'sensitive information', u'sent sunday', u'sent wednesday', u'apr subject', u'jacob subject', u'sent monday', u'foreign policy', u'foreign minister', u'cc sullivan', u'com sent', u'let know', u'national security', u'en route', u'com sullivan', u'news mahogany', u'http www', u'dec subject', u'cc subject', u'mailto clintonemail', u'sent saturday', u'abedinh state', u'valmorou state', u'sbwhoeop sent', u'human rights', u'feb subject', u'talk unclassified', u'cc huma', u'barack obama', u'january pm', u'mar subject', u'united states', u'date state', u'anne marie', u'sunday october', u'sent friday', u'cheryl subject', u'huma subject', u'march pm', u'subject unclassified', u'nov subject', u'new york', u'washington dc', u'gov sent', u'assistant secretary', u'produced house', u'release sullivan', u'original message', u'secretary state', u'sent tue', u'date unclassified', u'slaughtera state', u'clintonemail com', u'subject fw', u'redactions foia', u'oct subject', u'wednesday september', u'july pm', u'april pm', u'jan subject', u'jilotylc state', u'com abedin', u'saturday september', u'white house', u'waiver state', u'pm sullivanjj', u'sent mon', u'friday august', u'release jiloty', u'hillary clinton', u'house select', u'cheryl millscd', u'health care', u'pm cc', u'message abedin', u'date release', u'jiloty lauren', u'president obama', u'secretary clinton', u'october pm', u'huma abedinh', u'case doc', u'subject schedule', u'abedin subject', u'sent thu', u'sep subject', u'november pm', u'sullivan jacob', u'jake sullivan', u'message sullivan', u'obama administration', u'jun subject', u'cheryl mills', u'dept produced', u'message mills', u'secretary office', u'pm arrive', u'middle east', u'february pm', u'sent sun', u'slaughter anne', u'united nations', u'comm subject', u'el keib', u'pm mills', u'state dept', u'cc abedin', u'december pm', u'state unclassified', u'saturday october', u'release abedin', u'office pm', u'sent wed', u'vermarr state', u'mills cheryl'])\n",
      "0 :\n",
      "hanley monica\n",
      "waiver release\n",
      "sensitive source\n",
      "waiver unclassified\n",
      "source comment\n",
      "subject pdb\n",
      "friday september\n",
      "message hanley\n",
      "el magariaf\n",
      "hanleymr state\n",
      "\n",
      "1 :\n",
      "asking talk\n",
      "october subject\n",
      "called unclassified\n",
      "wants talk\n",
      "oscar flores\n",
      "holbrooke asking\n",
      "just called\n",
      "september subject\n",
      "confirmed unclassified\n",
      "holbrooke called\n",
      "\n",
      "2 :\n",
      "friends haiti\n",
      "au prince\n",
      "port au\n",
      "subject haiti\n",
      "conference friends\n",
      "friday january\n",
      "curtis meghann\n",
      "rights report\n",
      "report haiti\n",
      "reynoso julissa\n",
      "\n",
      "3 :\n",
      "subject office\n",
      "office autoreply\n",
      "access email\n",
      "immediate assistance\n",
      "need immediate\n",
      "cdm unclassified\n",
      "email need\n",
      "joanne laszczych\n",
      "nora toiv\n",
      "thank cdm\n",
      "\n",
      "4 :\n",
      "strobe talbott\n",
      "talbott sent\n",
      "praise haiti\n",
      "release strobe\n",
      "subject praise\n",
      "message strobe\n",
      "subject questions\n",
      "mutual friend\n",
      "brookings institution\n",
      "mon jan\n",
      "\n",
      "5 :\n",
      "release valmoro\n",
      "lona valmoro\n",
      "com valmoro\n",
      "special assistant\n",
      "valmoro special\n",
      "lona huma\n",
      "state direct\n",
      "lona sent\n",
      "message valmoro\n",
      "subject tomorrow\n",
      "\n",
      "6 :\n",
      "mr obama\n",
      "tea party\n",
      "john boehner\n",
      "george bush\n",
      "chief staff\n",
      "mother teresa\n",
      "care reform\n",
      "mrs clinton\n",
      "financial times\n",
      "republican party\n",
      "\n",
      "7 :\n",
      "subject list\n",
      "message jiloty\n",
      "mashabane update\n",
      "subject mashabane\n",
      "com jiloty\n",
      "lauren sent\n",
      "thu aug\n",
      "lauren subject\n",
      "ok original\n",
      "subject question\n",
      "\n",
      "8 :\n",
      "reinesp state\n",
      "fri aug\n",
      "harold hongju\n",
      "subject original\n",
      "philippe reinesp\n",
      "crowley philip\n",
      "koh harold\n",
      "feltman jeffrey\n",
      "steinberg james\n",
      "kelly craig\n",
      "\n",
      "9 :\n",
      "wed dec\n",
      "wednesday december\n",
      "thu dec\n",
      "thursday december\n",
      "secure fax\n",
      "tuesday december\n",
      "monday december\n",
      "tue dec\n",
      "fax line\n",
      "hang fax\n",
      "\n",
      "10 :\n",
      "declassify unclassified\n",
      "class confidential\n",
      "classified das\n",
      "das gis\n",
      "dos class\n",
      "gis dos\n",
      "reason declassify\n",
      "confidential reason\n",
      "burns william\n",
      "feltman jeffrey\n",
      "\n",
      "11 :\n",
      "turkey armenia\n",
      "armenia text\n",
      "text davutoglu\n",
      "subject turkey\n",
      "balderston kris\n",
      "sun aug\n",
      "sun jan\n",
      "balderstonkm state\n",
      "gordon philip\n",
      "kris balderstonkm\n",
      "\n",
      "12 :\n",
      "pm valmorou\n",
      "release huma\n",
      "subject shuttle\n",
      "hanleymr state\n",
      "huma clintonemail\n",
      "gov valmorou\n",
      "message valmorou\n",
      "message huma\n",
      "abedin valmorou\n",
      "subject tomorrow\n",
      "\n",
      "13 :\n",
      "release sbwhoeop\n",
      "guardian uk\n",
      "sid unclassified\n",
      "sinn fein\n",
      "www guardian\n",
      "message sbwhoeop\n",
      "power sharing\n",
      "hillary sid\n",
      "gordon brown\n",
      "issue statement\n",
      "\n",
      "14 :\n",
      "subject calls\n",
      "tue sep\n",
      "sat feb\n",
      "sat aug\n",
      "subject mubarak\n",
      "mubarak sheet\n",
      "subject oprah\n",
      "ok original\n",
      "oscar flores\n",
      "asking talk\n",
      "\n",
      "15 :\n",
      "verveer melanne\n",
      "verveerms state\n",
      "grameen bank\n",
      "women issues\n",
      "melanne verveerms\n",
      "message verveer\n",
      "release verveer\n",
      "melanne verveer\n",
      "global women\n",
      "melanne sent\n",
      "\n",
      "16 :\n",
      "billions aid\n",
      "buy little\n",
      "dollars buy\n",
      "goodwill pakistan\n",
      "little goodwill\n",
      "aid dollars\n",
      "mchaleja state\n",
      "foreign media\n",
      "judith mchaleja\n",
      "couple powerful\n",
      "\n",
      "17 :\n",
      "mills sent\n",
      "toiv nora\n",
      "cheryl cc\n",
      "subject talk\n",
      "pm millscd\n",
      "cdm unclassified\n",
      "mills subject\n",
      "kennedy patrick\n",
      "subject mills\n",
      "monday june\n",
      "\n",
      "18 :\n",
      "private residence\n",
      "conference room\n",
      "office time\n",
      "secretary conference\n",
      "meeting secretary\n",
      "staff meeting\n",
      "office daily\n",
      "national airport\n",
      "airport pm\n",
      "time pm\n",
      "\n",
      "19 :\n",
      "sullivan jacobi\n",
      "pm sullivan\n",
      "subject sullivan\n",
      "sullivann state\n",
      "jacob sullivann\n",
      "friday april\n",
      "sunday march\n",
      "sullivanil state\n",
      "subject question\n",
      "jacob sullivanil\n",
      "\n",
      "20 :\n",
      "west bank\n",
      "palestinian state\n",
      "east jerusalem\n",
      "security council\n",
      "peace talks\n",
      "peace process\n",
      "direct talks\n",
      "benjamin netanyahu\n",
      "american jewish\n",
      "direct negotiations\n",
      "\n",
      "21 :\n",
      "muscatinel state\n",
      "tuesday july\n",
      "lissa muscatinel\n",
      "lissa muscatine\n",
      "release muscatine\n",
      "message muscatine\n",
      "tue jul\n",
      "muscatine sent\n",
      "pm muscatine\n",
      "foreign affairs\n",
      "\n",
      "22 :\n",
      "trying ops\n",
      "subject trying\n",
      "richard vermarr\n",
      "thu dec\n",
      "release verma\n",
      "com verma\n",
      "message verma\n",
      "richard sent\n",
      "lew jacob\n",
      "cloakroom lift\n",
      "\n",
      "23 :\n",
      "marie slaughtera\n",
      "release slaughter\n",
      "marie slaughter\n",
      "message slaughter\n",
      "marie sent\n",
      "policy planning\n",
      "planning department\n",
      "director policy\n",
      "slaughter director\n",
      "jacob mills\n",
      "\n",
      "24 :\n",
      "mrs clinton\n",
      "food security\n",
      "public diplomacy\n",
      "heal africa\n",
      "climate change\n",
      "north korea\n",
      "civil society\n",
      "saudi arabia\n",
      "diplomacy development\n",
      "long term\n",
      "\n",
      "25 :\n",
      "thx unclassified\n",
      "pm jilotylc\n",
      "mills millscd\n",
      "preines subject\n",
      "pm cheryl\n",
      "pm millscd\n",
      "sullivanij state\n",
      "gov sullivanjj\n",
      "sunday march\n",
      "pm preines\n",
      "\n",
      "26 :\n",
      "cherie blair\n",
      "sullivan sent\n",
      "sent blackberry\n",
      "subject clintonemail\n",
      "release jake\n",
      "bam mikulski\n",
      "hanley monica\n",
      "mikulski bam\n",
      "food security\n",
      "windrush ventures\n",
      "\n",
      "27 :\n",
      "date draft\n",
      "draft unclassified\n",
      "release draft\n",
      "civilian power\n",
      "power unclassified\n",
      "leading civilian\n",
      "freedom speech\n",
      "affairs magazine\n",
      "foreign affairs\n",
      "magazine leading\n",
      "\n",
      "28 :\n",
      "pir preines\n",
      "release pir\n",
      "preines sent\n",
      "message evergreen\n",
      "evergreen pir\n",
      "pir subject\n",
      "message pir\n",
      "sri lanka\n",
      "sullivan subject\n",
      "subject interview\n",
      "\n",
      "29 :\n",
      "mahogany cc\n",
      "fw ap\n",
      "subject ap\n",
      "subject reuters\n",
      "fw reuters\n",
      "o_shift ii\n",
      "mahogany news\n",
      "ii sent\n",
      "o_shift iii\n",
      "ses ses\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualize results, print words with max sum of tf-idf in each cluster\n",
    "\n",
    "counter = CountVectorizer(strip_accents='unicode', ngram_range=(2,2), stop_words='english')\n",
    "\n",
    "#most n*5 frequent bigrams in all texts\n",
    "freq_words = set()\n",
    "res = counter.fit_transform(connected_texts).toarray()\n",
    "res = np.sum(res, axis=0)\n",
    "terms = {} #index to word\n",
    "for z in counter.vocabulary_:\n",
    "    terms[counter.vocabulary_[z]] = z\n",
    "for k in xrange(n*5):\n",
    "    j = np.unravel_index(res.argmax(), res.shape)[0]\n",
    "    freq_words.add(terms[j])\n",
    "    res[j] = 0\n",
    "\n",
    "counter = TfidfVectorizer(strip_accents='unicode', ngram_range=(2,2), stop_words='english')\n",
    "#most sum of tf-idf bigrams\n",
    "res = counter.fit_transform(connected_texts).toarray()\n",
    "res = np.sum(res, axis=0)\n",
    "terms = {} #index to word\n",
    "for z in counter.vocabulary_:\n",
    "    terms[counter.vocabulary_[z]] = z\n",
    "for k in xrange(n*5):\n",
    "    j = np.unravel_index(res.argmax(), res.shape)[0]\n",
    "    freq_words.add(terms[j])\n",
    "    res[j] = 0\n",
    "print freq_words\n",
    "\n",
    "#clusterization visualize\n",
    "for i in xrange(n):\n",
    "    print i, \":\"\n",
    "    cluster_texts = []\n",
    "    for j, text in enumerate(connected_texts):\n",
    "        if result[j] == i:\n",
    "            cluster_texts.append(text)\n",
    "    res = counter.fit_transform(cluster_texts).toarray()\n",
    "    res = np.sum(res, axis = 0)\n",
    "    terms = {}\n",
    "    for z in counter.vocabulary_:\n",
    "        terms[counter.vocabulary_[z]] = z\n",
    "    #10 top sum tf-idf words\n",
    "    k = 0\n",
    "    while k < 10:\n",
    "        j = np.unravel_index(res.argmax(), res.shape)[0]\n",
    "        if not (terms[j] in freq_words):\n",
    "            print terms[j]\n",
    "            k += 1\n",
    "        res[j] = 0\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Кластеры уже похожи на интерпретируемые.\n",
    "\n",
    "Пусть ассесоры просматривают письма из кластера и отвечают на вопрос: \"письмам из кластера можно назначить общую тему?\"\n",
    "0 - нельзя\n",
    "0.5 - нет сильной уверенности, что предложенная ассесорам тема их объеденяет\n",
    "1 - ассесор уверен в теме, которую назначил кластеру\n",
    "\n",
    "Результаты ассесора: 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
